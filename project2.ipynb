{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1781055-5c53-4eb1-9235-beabecaebaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49e175-486b-4ffe-a5fc-58c0fe688eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU transformers accelerate einops langchain xformers bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee75c8c-a178-413b-bc60-f91af6c68176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4153d-a31c-40e5-bc1f-4733170d56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9239fc2-63f4-4c01-94d8-ce99a15f590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bac17-6973-4c06-99b6-2304fa09d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU transformers accelerate einops langchain xformers bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ba0dc-faa9-4bd9-b133-e4af964c062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f48a9c71-a769-4707-9ec6-e4b710fbfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import pickle\n",
    "import transformers\n",
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561713ed-ff51-4f93-bc82-5f38d1efdd70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16,\n",
    "    load_in_8bit_fp32_cpu_offload=True,\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "hf_auth = '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'\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c88f59e-74e0-4bbe-839f-0e2ca173e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34a1d5b87cf40199829294095749e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        \"/scratch/lora.n/STS_Project/l2tune\",\n",
    "        #\"/scratch/lora.n/LLaMa2/config.py\",\n",
    "        #from_tf = True,\n",
    "        cache_dir='/scratch/lora.n/LLaMa2',\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto',\n",
    "        token=hf_auth\n",
    "    )\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04152952-0681-4629-a676-b038b29b7a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5368365-df97-4e48-ac14-331582623e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a140f1ad-4253-406d-b187-20997c5a9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 29871, 13, 29950, 7889, 29901], [1, 29871, 13, 28956, 13]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_list = ['\\nHuman:', '\\n```\\n']\n",
    "\n",
    "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
    "stop_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a440a4-44d8-4bcb-8e95-0134e32f8287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([    1, 29871,    13, 29950,  7889, 29901], device='cuda:0'),\n",
       " tensor([    1, 29871,    13, 28956,    13], device='cuda:0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "stop_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a91aa4-9aa0-4cf2-9193-9f2c4dda098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac53aa9-1190-441a-8aac-b11ff2e7cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "pipe = transformers.pipeline(model=model, tokenizer=tokenizer, torch_dtype=torch.bfloat16, return_full_text=True,  \n",
    "task='text-generation', stopping_criteria=stopping_criteria,  temperature=0.8, max_new_tokens=600, repetition_penalty=1.1)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ec97e71-1d3e-4d5d-a8e9-7a1093289945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<>\\n\", \"\\n<>\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f417316-c7f7-4452-87cf-c0f6a2a24069",
   "metadata": {},
   "source": [
    "MAIN LOOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aef781c-40d1-433f-9969-5142710c64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(instruction, new_system_prompt):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8920eaea-548b-461b-ab1b-ebb86afdab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GameRepeat(context, code):\n",
    "    #initialize game and scenario\n",
    "    scen = open(context +'.txt').read()\n",
    "    game = open(code  +'.txt').read()\n",
    "    \n",
    "    #initialize system message\n",
    "    sys_msg = B_SYS + \"Consider the proposed scenario and act as if you were taking part in it. \\n\"+ scen + E_SYS\n",
    "    #initalize user message\n",
    "    cmds = B_INST + \" Respond to the following using exactly one letter to denote your choice. Your answer must either consist of the letter 'C' for strategy C or 'D' for strategy D.\" + E_INST\n",
    "    human_msg = cmds + \"\\nUser: {user_input}\"\n",
    "       \n",
    "    template = get_prompt(human_msg, sys_msg)\n",
    "    prompt = PromptTemplate(input_variables=[\"user_input\"], template=template)\n",
    "    lm = LLMChain(llm=llm,prompt=prompt,verbose=False, memory=None)\n",
    "    \n",
    "    stratlist =[]\n",
    "    for i in range(0,300):\n",
    "        rz = lm.predict(user_input = game)\n",
    "        stratlist.append(rz)\n",
    "    return stratlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6537cb9-b7a5-41b1-b0c0-3c6407761d26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'input'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m scenarios:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m game \u001b[38;5;129;01min\u001b[39;00m games:\n\u001b[0;32m----> 8\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m \u001b[43mGameRepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         results_7b\u001b[38;5;241m.\u001b[39mupdate({scenario\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mgame:gamma})\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7b-fixed-results.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mGameRepeat\u001b[0;34m(context, code)\u001b[0m\n\u001b[1;32m     16\u001b[0m stratlist \u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     rz \u001b[38;5;241m=\u001b[39m \u001b[43mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     stratlist\u001b[38;5;241m.\u001b[39mappend(rz)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stratlist\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain/chains/llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain/chains/base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    361\u001b[0m }\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain/chains/base.py:138\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m include_run_info \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_run_info\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    136\u001b[0m return_only_outputs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_only_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 138\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    140\u001b[0m     callbacks,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain/chains/base.py:475\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     external_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mload_memory_variables(inputs)\n\u001b[1;32m    474\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexternal_context)\n\u001b[0;32m--> 475\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/.conda/envs/deepseek/lib/python3.10/site-packages/langchain/chains/base.py:264\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'input'}"
     ]
    }
   ],
   "source": [
    "scenarios = ['IR', 'biz', 'friendsharing', 'environment', 'team'] \n",
    "games = ['prison', 'delight', 'staghunt', 'snowdrift']\n",
    "\n",
    "results_7b = {}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for game in games:\n",
    "        gamma = GameRepeat(scenario, game)\n",
    "        results_7b.update({scenario+\"_\"+game:gamma})\n",
    "\n",
    "with open('7b-fixed-results.txt', 'wb') as file:\n",
    "    pickle.dump(results_7b, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df3d32b9-f3c6-41ef-b8e7-4c6510fe50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook project2.ipynb to script\n",
      "[NbConvertApp] Writing 5173 bytes to project2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert project2.ipynb --to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d79d1-19c0-4611-bd99-0111e4f4a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
