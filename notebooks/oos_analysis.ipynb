{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['sports_prison', 'sports_delight', 'sports_staghunt', 'sports_snowdrift', 'roomsharing_prison', 'roomsharing_delight', 'roomsharing_staghunt', 'roomsharing_snowdrift', 'ventcap_prison', 'ventcap_delight', 'ventcap_staghunt', 'ventcap_snowdrift'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle \n",
    "import re\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Sample data dictionary (replace this with your actual data)\n",
    "\n",
    "llm = '7b-fixed'\n",
    "\n",
    "data = pickle.load(open(os.path.join(\"../oos_context/\", llm+\"-results-oos.txt\"), \"rb\" ))\n",
    "\n",
    "# data type\n",
    "print(type(data))\n",
    "\n",
    "# data info\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for invalid values\n",
    "for key in data.keys():\n",
    "    for item in data[key]:\n",
    "        if item != '  C' and item != '  D':\n",
    "            print(key, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution saved to 70b-fixed_distribution.txt\n"
     ]
    }
   ],
   "source": [
    "# create a function to show the distribution of the data\n",
    "# return a dictionary, with keys as the keys of the input dictionary, and values as the distribution of the data\n",
    "def show_distribution(data):\n",
    "    distribution = {}\n",
    "    for key in data.keys():\n",
    "        distribution[key] = {}\n",
    "        for item in data[key]:\n",
    "            if item not in distribution[key]:\n",
    "                distribution[key][item] = 1\n",
    "            else:\n",
    "                distribution[key][item] += 1\n",
    "    return distribution\n",
    "\n",
    "# show the distribution of the data\n",
    "distribution = show_distribution(data)\n",
    "\n",
    "# save the distribution to a .txt file\n",
    "# with open(os.path.join(\"../oos-context/\", llm+\"_distribution.txt\"), \"x\") as f:\n",
    "#     for key in distribution.keys():\n",
    "#         # write each line like this: key: {item1: count1, item2: count2}\n",
    "#         f.write(key + ': ' + str(distribution[key]) + '\\n')\n",
    "\n",
    "# print('Distribution saved to ' + llm + '_distribution.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary from .txt file\n",
    "def read_distribution(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    distribution = {}\n",
    "    for line in lines:\n",
    "        # each line is like this: key: {item1: count1, item2: count2}\n",
    "        # first, split by the first ': ' to get the key\n",
    "        # then, split by the '{' and '}' to get the value\n",
    "        key, value = line.split(': {')\n",
    "        value = value[0:-2].split(', ')\n",
    "        value = {item.split(': ')[0][1:-1]: int(item.split(': ')[1]) for item in value}\n",
    "        distribution[key] = value\n",
    "    return distribution\n",
    "\n",
    "# show the distribution\n",
    "# print(distribution)\n",
    "\n",
    "all_data = {}\n",
    "llms = ['7b-fixed', '7b-fined', '70b-fixed']\n",
    "for llm in llms:\n",
    "    distribution = read_distribution(os.path.join(\"../oos_context\", llm+\"_distribution.txt\"))\n",
    "    all_data[llm] = distribution\n",
    "    \n",
    "# # save the all_data dictionary to a .txt file\n",
    "# with open(os.path.join(\"../oos_context\", \"all_data_reasoning.txt\"), \"w\") as f:\n",
    "#     f.write(str(all_data))\n",
    "    \n",
    "# print('All data saved to all_data.txt')\n",
    "\n",
    "# # save to a .pkl file\n",
    "# pickle.dump(all_data, open(os.path.join(\"../oos_context\", \"all_data_reasoning.pkl\"), \"wb\"))\n",
    "\n",
    "# print('All data saved to all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sports_prison', 'sports_delight', 'sports_staghunt', 'sports_snowdrift', 'roomsharing_prison', 'roomsharing_delight', 'roomsharing_staghunt', 'roomsharing_snowdrift', 'ventcap_prison', 'ventcap_delight', 'ventcap_staghunt', 'ventcap_snowdrift']\n"
     ]
    }
   ],
   "source": [
    "def compare_distribution_for_each_game(all_data, game):\n",
    "    plt.figure()\n",
    "    bar_width = 0.2  # Width of each bar\n",
    "    bar_positions = []  # List to store the x positions of bars\n",
    "\n",
    "    for index, llm in enumerate(all_data.keys()):\n",
    "        valid_keys = all_data[llm][game].keys()\n",
    "        # Generate x positions for bars\n",
    "        x = [pos + bar_width * index for pos in range(len(valid_keys))]\n",
    "        bar_positions.append(x)\n",
    "        # color = 'b' if llm == '7b_org' else 'orange' if llm == '7b_finetuned' else 'red'\n",
    "        color = 'blue' if llm == '7b-fixed' else 'orange' if llm == '7b-fined' else 'green'\n",
    "        plt.bar(x, all_data[llm][game].values(), width=bar_width, alpha=0.5, label=llm, color=color)\n",
    "\n",
    "    # Adjust xticks to the middle of the grouped bars\n",
    "    plt.xticks([pos + bar_width * (len(all_data) - 1) / 2 for pos in range(len(valid_keys))], valid_keys)\n",
    "\n",
    "    plt.xlabel(game)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(game + ' distribution')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# compare the distribution of different models\n",
    "def compare_distribution(all_data, keys):\n",
    "    for key in keys:\n",
    "        compare_distribution_for_each_game(all_data, key)\n",
    "        print(key)\n",
    "\n",
    "# compare the distribution of different models\n",
    "keys = [item for item in data.keys()]\n",
    "print(keys)\n",
    "compare_distribution(all_data, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'sports': ['sports_prison',\n",
       "              'sports_delight',\n",
       "              'sports_staghunt',\n",
       "              'sports_snowdrift'],\n",
       "             'roomsharing': ['roomsharing_prison',\n",
       "              'roomsharing_delight',\n",
       "              'roomsharing_staghunt',\n",
       "              'roomsharing_snowdrift'],\n",
       "             'ventcap': ['ventcap_prison',\n",
       "              'ventcap_delight',\n",
       "              'ventcap_staghunt',\n",
       "              'ventcap_snowdrift']})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "categorized_keys = defaultdict(list)\n",
    "for item in keys:\n",
    "    prefix = item.split('_')[0]  # Get the prefix before the underscore\n",
    "    categorized_keys[prefix].append(item)\n",
    "# 0 is for context, 1 is for game\n",
    "\n",
    "# Extract values from the dictionary to get the list of lists\n",
    "categorized_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b-fixed sports_prison 239 0.0\n",
      "7b-fixed sports_delight 234 1.0\n",
      "7b-fixed sports_staghunt 238 2.0\n",
      "7b-fixed sports_snowdrift 237 3.0\n",
      "7b-fined sports_prison 208 0.2\n",
      "7b-fined sports_delight 221 1.2\n",
      "7b-fined sports_staghunt 212 2.2\n",
      "7b-fined sports_snowdrift 203 3.2\n",
      "70b-fixed sports_prison 0 0.4\n",
      "70b-fixed sports_delight 37 1.4\n",
      "70b-fixed sports_staghunt 0 2.4\n",
      "70b-fixed sports_snowdrift 0 3.4\n",
      "['sports_prison', 'sports_delight', 'sports_staghunt', 'sports_snowdrift']\n",
      "['prison', 'delight', 'staghunt', 'snowdrift']\n",
      "7b-fixed roomsharing_prison 261 0.0\n",
      "7b-fixed roomsharing_delight 261 1.0\n",
      "7b-fixed roomsharing_staghunt 264 2.0\n",
      "7b-fixed roomsharing_snowdrift 248 3.0\n",
      "7b-fined roomsharing_prison 224 0.2\n",
      "7b-fined roomsharing_delight 223 1.2\n",
      "7b-fined roomsharing_staghunt 239 2.2\n",
      "7b-fined roomsharing_snowdrift 229 3.2\n",
      "70b-fixed roomsharing_prison 82 0.4\n",
      "70b-fixed roomsharing_delight 203 1.4\n",
      "70b-fixed roomsharing_staghunt 168 2.4\n",
      "70b-fixed roomsharing_snowdrift 140 3.4\n",
      "['roomsharing_prison', 'roomsharing_delight', 'roomsharing_staghunt', 'roomsharing_snowdrift']\n",
      "['prison', 'delight', 'staghunt', 'snowdrift']\n",
      "7b-fixed ventcap_prison 245 0.0\n",
      "7b-fixed ventcap_delight 244 1.0\n",
      "7b-fixed ventcap_staghunt 234 2.0\n",
      "7b-fixed ventcap_snowdrift 258 3.0\n",
      "7b-fined ventcap_prison 227 0.2\n",
      "7b-fined ventcap_delight 234 1.2\n",
      "7b-fined ventcap_staghunt 231 2.2\n",
      "7b-fined ventcap_snowdrift 218 3.2\n",
      "70b-fixed ventcap_prison 31 0.4\n",
      "70b-fixed ventcap_delight 142 1.4\n",
      "70b-fixed ventcap_staghunt 110 2.4\n",
      "70b-fixed ventcap_snowdrift 53 3.4\n",
      "['ventcap_prison', 'ventcap_delight', 'ventcap_staghunt', 'ventcap_snowdrift']\n",
      "['prison', 'delight', 'staghunt', 'snowdrift']\n"
     ]
    }
   ],
   "source": [
    "def aggregated_comparison_by_category(all_data, category, category_type):\n",
    "    llms = all_data.keys()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bar_width = 0.2\n",
    "    llm_colors = {'7b-fixed': 'blue', '7b-fined': 'orange', '70b-fixed': 'green'}  # Add colors for other LLMs as needed\n",
    "    legend_handles = []\n",
    "    \n",
    "    for index, llm in enumerate(llms):\n",
    "        distribution = all_data[llm]\n",
    "\n",
    "        # filter games in distribution that have the context in the name\n",
    "        valid_games = [game for game in distribution.keys() if category in game]\n",
    "        \n",
    "        # set the x positions for bars\n",
    "        x = [pos + bar_width * index for pos in range(len(valid_games))]\n",
    "        \n",
    "        for i, game in enumerate(valid_games):\n",
    "            # only show the value for key: '  C'\n",
    "            color = llm_colors[llm]\n",
    "            print(llm, game, distribution[game]['  C'], x[i])\n",
    "            plt.bar(x[i], distribution[game]['  C'], width=bar_width, alpha=0.5, label=game, color=color)\n",
    "            \n",
    "        # Add legend entry for current LLM\n",
    "        legend_handles.append(plt.Rectangle((0, 0), 1, 1, fc=color, alpha=0.5, edgecolor='none'))\n",
    "    \n",
    "    # edited valid games should remove its context part if the category is 'Context'\n",
    "    # edited valid games should remove its game part if the category is 'Game'\n",
    "    if category_type == 'Game':\n",
    "        edited_valid_games = [re.sub(r'_.*', '', game) for game in valid_games]\n",
    "    else:\n",
    "        edited_valid_games = [re.sub(r'.*_', '', game) for game in valid_games]\n",
    "    print(valid_games)\n",
    "    print(edited_valid_games)\n",
    "    valid_games = edited_valid_games\n",
    "    \n",
    "    plt.xticks([pos + bar_width * (len(valid_games) - 1) / 3 for pos in range(len(valid_games))], valid_games, fontsize=15)\n",
    "    # set the xticks size to be larger\n",
    "    \n",
    "    plt.xlabel(category, fontsize=15)\n",
    "    plt.ylabel('Cooperation', fontsize=15)\n",
    "    plt.title(f'{category_type} {category} distribution', fontdict={'fontsize': 16})\n",
    "    plt.legend(legend_handles, llms, loc='lower right', title='LLM')\n",
    "    # plt.show()\n",
    "    # save plot\n",
    "    if category_type == 'Context':\n",
    "        plt.savefig(os.path.join(\"../oos_figs/context\", category + '_distribution.png'))\n",
    "    else:\n",
    "        plt.savefig(os.path.join(\"../oos_figs/game\", category + '_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "for category in categorized_keys:\n",
    "    aggregated_comparison_by_category(all_data, category, category_type='Context')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images merged and saved to ../oos_figs/context_distribution.png\n"
     ]
    }
   ],
   "source": [
    "def merge_images(folder_path, output_path):\n",
    "    # merge three .png files into one .png file, using the following layout:\n",
    "    # 1 2\n",
    "    #  3\n",
    "\n",
    "    # get all the .png files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    files.sort()\n",
    "    \n",
    "    # open all the images\n",
    "    images = [Image.open(os.path.join(folder_path, f)) for f in files]\n",
    "    \n",
    "    # get the size of the images\n",
    "    width, height = images[0].size\n",
    "    total_width = 2 * width\n",
    "    total_height = 2 * height\n",
    "    \n",
    "    # create a new image with the size of the merged image\n",
    "    new_image = Image.new('RGB', (total_width, total_height))\n",
    "    \n",
    "    # paste the images to the new image\n",
    "    new_image.paste(images[0], (0, 0))\n",
    "    new_image.paste(images[1], (width, 0))\n",
    "    new_image.paste(images[2], (width // 2, height))\n",
    "        \n",
    "    \n",
    "    # make the empty space in the left and right of the middle image white\n",
    "    for j in range(height):\n",
    "        for i in range(width//2):\n",
    "            new_image.putpixel((i, height + j), (255, 255, 255))\n",
    "        for i in range(width*3//2, 2*width):\n",
    "            new_image.putpixel((i, height + j), (255, 255, 255))\n",
    "       \n",
    "    # save the new image\n",
    "    new_image.save(output_path)\n",
    "    print('Images merged and saved to ' + output_path)\n",
    "\n",
    "merge_images(os.path.join(\"../oos_figs/context\"), os.path.join(\"../oos_figs\", \"context_distribution.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images merged and saved to ../oos_figs/game_distribution.png\n"
     ]
    }
   ],
   "source": [
    "def merge_images_of_four(folder_path, output_path):\n",
    "    # merge four .png files into one .png file, using the following layout:\n",
    "    # 1 2\n",
    "    # 3 4\n",
    "    \n",
    "    # get all the .png files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    files.sort()\n",
    "    \n",
    "    # open all the images\n",
    "    images = [Image.open(os.path.join(folder_path, f)) for f in files]\n",
    "    \n",
    "    # get the size of the images\n",
    "    width, height = images[0].size\n",
    "    total_width = 2 * width\n",
    "    total_height = 2 * height\n",
    "    \n",
    "    # create a new image with the size of the merged image\n",
    "    new_image = Image.new('RGB', (total_width, total_height))\n",
    "    \n",
    "    # paste the images to the new image\n",
    "    new_image.paste(images[0], (0, 0))\n",
    "    new_image.paste(images[1], (width, 0))\n",
    "    new_image.paste(images[2], (0, height))\n",
    "    new_image.paste(images[3], (width, height))\n",
    "    \n",
    "    # save the new image\n",
    "    new_image.save(output_path)\n",
    "    print('Images merged and saved to ' + output_path)\n",
    "    \n",
    "merge_images_of_four(os.path.join(\"../oos_figs/game\"), os.path.join(\"../oos_figs\", \"game_distribution.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../oos_figs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimprovement.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), dpi\u001b[38;5;241m=\u001b[39mmy_dpi)\n\u001b[1;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 31\u001b[0m compare_progress(\u001b[43mall_data\u001b[49m, keys)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "# for each game and context, the goal of finetuning was to reach the results of the 70b model\n",
    "# so the initial model is 7b_org, the finetuned model is 7b_finetuned, and the target model is 70b\n",
    "# given this, compare the progress of 7b_org and 7b_finetuned towards 70b by this formula:\n",
    "# progress = (7b_finetuned - 7b_org) / (70b - 7b_org) * 100\n",
    "\n",
    "def compare_progress(all_data, keys):\n",
    "    my_dpi = 96\n",
    "    plt.figure(figsize=(800/my_dpi, 400/my_dpi), dpi=my_dpi)\n",
    "\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    bar_width = 0.2\n",
    "    bar_positions = []\n",
    "\n",
    "    progress = [(all_data['7b-fined'][key]['  C'] - all_data['7b-fixed'][key]['  C']) / (all_data['70b-fixed'][key]['  C'] - all_data['7b-fixed'][key]['  C']) * 100 for key in keys]\n",
    "    x = [pos for pos in range(len(keys))]        \n",
    "    plt.bar(x, progress, width=bar_width, alpha=0.5, label='Improvement', color='blue')\n",
    "    # draw a line at y=100\n",
    "    plt.axhline(y=100, color='red', linestyle='--', label='100%')\n",
    "    # plot logaritmic scale\n",
    "    # plt.yscale('log')\n",
    "    # plt.axhline(y=0, color='black', linestyle='--', label='0%')\n",
    "    plt.xticks([pos for pos in range(len(keys))], keys, rotation=90)\n",
    "    plt.xlabel('Game')\n",
    "    plt.ylabel('Improvement (%)')\n",
    "    plt.title('Relative Change in Cooperation per Game and Context')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(os.path.join(\"../oos_figs\", \"improvement.png\"), dpi=my_dpi)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "compare_progress(all_data, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Game': ['sports_prison', 'sports_delight', 'sports_staghunt', 'sports_snowdrift', 'roomsharing_prison', 'roomsharing_delight', 'roomsharing_staghunt', 'roomsharing_snowdrift', 'ventcap_prison', 'ventcap_delight', 'ventcap_staghunt', 'ventcap_snowdrift'], 'Improvement (%)': [12.97071129707113, 6.598984771573605, 10.92436974789916, 14.345991561181433, 20.670391061452513, 65.51724137931035, 26.041666666666668, 17.59259259259259, 8.411214953271028, 9.803921568627452, 2.4193548387096775, 19.51219512195122]}\n",
      "Table saved to improvement_table.csv\n",
      "Mean: 17.90071963002557\n",
      "Median: 13.65835142912628\n",
      "Standard deviation: 16.3834513887361\n"
     ]
    }
   ],
   "source": [
    "# visualize the progress of 7b_org and 7b_finetuned towards 70b in a table\n",
    "\n",
    "def compare_progress_table(all_data, keys):\n",
    "    progress = [(all_data['7b-fined'][key]['  C'] - all_data['7b-fixed'][key]['  C']) / (all_data['70b-fixed'][key]['  C'] - all_data['7b-fixed'][key]['  C']) * 100 for key in keys]\n",
    "    new_keys = keys.copy()\n",
    "    # # drop these keys from x and progress\n",
    "    # # environment_staghunt_oos, environment_delight_oos, friendsharing_staghunt_oos, friendsharing_delight_oos\n",
    "    # new_keys.remove('environment_staghunt_oos')\n",
    "    # new_keys.remove('environment_delight_oos')\n",
    "    # new_keys.remove('friendsharing_staghunt_oos')\n",
    "    # new_keys.remove('friendsharing_delight_oos')\n",
    "    # progress.pop(keys.index('environment_staghunt_oos'))\n",
    "    # progress.pop(keys.index('environment_delight_oos'))\n",
    "    # progress.pop(keys.index('friendsharing_staghunt_oos'))\n",
    "    # progress.pop(keys.index('friendsharing_delight_oos'))\n",
    "    \n",
    "    # create a table\n",
    "    table = {}\n",
    "    table['Game'] = new_keys\n",
    "    table['Improvement (%)'] = progress\n",
    "    return table\n",
    "\n",
    "table = compare_progress_table(all_data, keys)\n",
    "print(table)\n",
    "\n",
    "# visualize the table\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "df.to_csv(os.path.join(\"../oos_context_figs\", \"improvement_table.csv\"), index=False)\n",
    "print('Table saved to improvement_table.csv')\n",
    "\n",
    "# print the mean and standard deviation of the progress\n",
    "print('Mean:', df['Improvement (%)'].mean())\n",
    "print('Median:', df['Improvement (%)'].median())\n",
    "print('Standard deviation:', df['Improvement (%)'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
